//
// Generated by LLVM NVPTX Back-End
//

.version 7.0
.target sm_80
.address_size 64

	// .weak	cudaMalloc

.weak .func  (.param .b32 func_retval0) cudaMalloc(
	.param .b64 cudaMalloc_param_0,
	.param .b64 cudaMalloc_param_1
)
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, 999;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .weak	cudaFuncGetAttributes
.weak .func  (.param .b32 func_retval0) cudaFuncGetAttributes(
	.param .b64 cudaFuncGetAttributes_param_0,
	.param .b64 cudaFuncGetAttributes_param_1
)
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, 999;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .weak	cudaDeviceGetAttribute
.weak .func  (.param .b32 func_retval0) cudaDeviceGetAttribute(
	.param .b64 cudaDeviceGetAttribute_param_0,
	.param .b32 cudaDeviceGetAttribute_param_1,
	.param .b32 cudaDeviceGetAttribute_param_2
)
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, 999;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .weak	cudaGetDevice
.weak .func  (.param .b32 func_retval0) cudaGetDevice(
	.param .b64 cudaGetDevice_param_0
)
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, 999;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessor
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessor(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_3
)
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, 999;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_3,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_4
)
{
	.reg .b32 	%r<2>;

	mov.u32 	%r1, 999;
	st.param.b32 	[func_retval0+0], %r1;
	ret;

}
	// .globl	_Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc
.visible .entry _Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc(
	.param .u64 _Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_0,
	.param .u64 _Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_1,
	.param .u64 _Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_2,
	.param .u32 _Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_3,
	.param .u32 _Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_4,
	.param .u64 _Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<14>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<30>;

	ld.param.u32 	%r9, [_Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_3];
	setp.gt.s32 	%p1, %r9, 255;
	@%p1 bra 	LBB6_8;
	ld.param.u32 	%r8, [_Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_4];
	mov.u32 	%r1, %tid.x;
	and.b32  	%r10, %r1, 31;
	shl.b32 	%r11, %r8, 6;
	and.b32  	%r12, %r11, 1073741760;
	or.b32  	%r2, %r10, %r12;
	setp.gt.u32 	%p2, %r2, 255;
	@%p2 bra 	LBB6_8;
	ld.param.u64 	%rd15, [_Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_2];
	cvta.to.global.u64 	%rd1, %rd15;
	and.b32  	%r3, %r1, 992;
	add.s32 	%r13, %r1, 32;
	and.b32  	%r4, %r13, 2016;
	setp.ge.u32 	%p3, %r3, %r4;
	mov.f32 	%f13, 0f00000000;
	@%p3 bra 	LBB6_5;
	ld.param.u64 	%rd14, [_Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_0];
	ld.param.u64 	%rd16, [_Z48Dot_float_float_float_cuda_Dot_8157_block_kernelPfS_S_iiPc_param_1];
	cvta.to.global.u64 	%rd2, %rd16;
	cvta.to.global.u64 	%rd3, %rd14;
	shl.b32 	%r14, %r1, 8;
	and.b32  	%r15, %r14, 253952;
	add.s32 	%r16, %r2, %r15;
	add.s32 	%r17, %r16, 256;
	mul.wide.u32 	%rd17, %r17, 4;
	add.s64 	%rd29, %rd2, %rd17;
	sub.s32 	%r19, %r4, %r3;
	cvt.u64.u32 	%rd18, %r2;
	cvt.u64.u32 	%rd19, %r15;
	add.s64 	%rd20, %rd18, %rd19;
	shl.b64 	%rd21, %rd20, 2;
	add.s64 	%rd28, %rd2, %rd21;
	cvt.u64.u32 	%rd22, %r1;
	and.b64  	%rd23, %rd22, 992;
	shl.b64 	%rd24, %rd23, 2;
	add.s64 	%rd25, %rd24, %rd3;
	add.s64 	%rd27, %rd25, 4;
	mov.f32 	%f13, 0f00000000;
LBB6_4:
	ld.global.f32 	%f6, [%rd27+-4];
	ld.global.f32 	%f7, [%rd28];
	fma.rn.f32 	%f8, %f6, %f7, %f13;
	ld.global.f32 	%f9, [%rd27];
	ld.global.f32 	%f10, [%rd29];
	fma.rn.f32 	%f13, %f9, %f10, %f8;
	add.s64 	%rd29, %rd29, 2048;
	add.s32 	%r19, %r19, -2;
	add.s64 	%rd28, %rd28, 2048;
	add.s64 	%rd27, %rd27, 8;
	setp.eq.s32 	%p4, %r19, 0;
	@%p4 bra 	LBB6_5;
	bra.uni 	LBB6_4;
LBB6_5:
	setp.lt.u32 	%p5, %r1, 32;
	mul.wide.u32 	%rd26, %r2, 4;
	add.s64 	%rd7, %rd1, %rd26;
	@%p5 bra 	LBB6_6;
	bra.uni 	LBB6_7;
LBB6_6:
	mov.u32 	%r18, 0;
	st.global.u32 	[%rd7], %r18;
LBB6_7:
	bar.sync 	0;
	atom.global.add.f32 	%f11, [%rd7], %f13;
LBB6_8:
	ret;

}
